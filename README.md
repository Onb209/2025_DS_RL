# Reinforcement Learning Algorithms in GridWorld

This repository contains hands-on practice code for reinforcement learning (RL) algorithms, designed to support educational lectures and tutorials. It provides implementations and experiments for key RL methods in a discrete GridWorld environment.

Implemented algorithms include:

- **Policy Iteration**
- **Value Iteration**


![ex](assets/render_img.png)

---
## Policy Iteration

**Policy Evaluation**  
![value iteration equation](https://latex.codecogs.com/png.image?\dpi{150}&space;v_{k+1}(s)&space;=&space;\sum_{a&space;\in&space;\mathcal{A}}&space;\pi(a|s)&space;\left(&space;\mathcal{R}_s^a&space;+&space;\gamma&space;\sum_{s'\in&space;\mathcal{S}}&space;\mathcal{P}_{ss'}^a&space;v_k(s')&space;\right)
)



**Policy Improvement**  
![Policy Improvement](https://latex.codecogs.com/png.image?\dpi{120}&space;\pi_{\text{new}}(s)=\arg\max_a\sum_{s'}P(s'|s,a)[R(s,a,s')+\gamma&space;V^\pi(s')])


## Value Iteration

![Value Update](https://latex.codecogs.com/png.image?\dpi{120}&space;V(s)=\max_a\sum_{s'}P(s'|s,a)[R(s,a,s')+\gamma&space;V(s')])

![Policy from Value](https://latex.codecogs.com/png.image?\dpi{120}&space;\pi^*(s)=\arg\max_a\sum_{s'}P(s'|s,a)[R(s,a,s')+\gamma&space;V^*(s')])


---

## ğŸŒ GridWorld

The GridWorld environment is a 2D grid where each cell can be one of the following types:

- ğŸŸ© **Normal**: The agent can move to a normal cell with a reward of -1.
- ğŸ§± **Wall**: The agent cannot move into a wall cell. The agent stays in its current position and receives a reward of -1.
- â˜ ï¸ **Trap**: If the agent moves into a trap cell, it receives a reward of -100, and the episode ends.
- ğŸ¯ **Goal**: If the agent reaches the goal cell, it receives a reward of 100, and the episode ends.

### ğŸ“ Grid Dimensions

- The grid size can range from **5x5** to **10x10**.

### ğŸƒâ€â™‚ï¸ Actions

- The agent has 4 possible actions:  
  - â¬†ï¸ **Move Up**  
  - â¬‡ï¸ **Move Down**  
  - â¬…ï¸ **Move Left**  
  - â¡ï¸ **Move Right**

---

## ğŸ› ï¸ Installation

We recommend using a virtual environment for package management. This project has been tested on **Ubuntu 20.04** with **Python 3.10**.

```bash
# Clone the repository and navigate to the project folder
cd {project_folder}

# Create and activate a virtual environment
python3.10 -m venv venv
source venv/bin/activate

# Install required packages
pip install pygame numpy matplotlib pillow
```
---

## ğŸš€ Training
To train an RL agent, run the train.py script with the desired algorithm and optional arguments.
```bash
python train.py --algo {algorithm} [--size SIZE] [--random] [--render]
```
**Arguments**
- --algo (str, required): Choose the learning algorithm.
  - Options: pi, vi
- --size (int, optional): Width & Height of the GridWorld. Default is 6.
- --random (flag, optional): Use randomly generated map.
- --render (flag, optional): Render the environment during training.

The trained policy will be saved in the checkpoints/ directory as a .pkl file.


![Output](assets/animation.gif)

---

## ğŸ–¼ï¸ Rendering a Trained Policy
You can visualize a learned policy using the render.py script:
```bash
python render.py --policy {path_to_policy.pkl} [--size SIZE] [--random]

## ğŸ“ Folder Structure
```bash
.
â”œâ”€â”€ train.py               # Main training script
â”œâ”€â”€ render.py              # Visualization script
â”œâ”€â”€ checkpoints/           # Saved policy files
â”œâ”€â”€ env/                   # GridWorld environment
â”‚   â””â”€â”€ maps/              # Predefined map configurations
â”œâ”€â”€ outputs/               # Plotted value tables and action maps
â”œâ”€â”€ venv/                  # Virtual environment folder
â”œâ”€â”€ algos/                 # Folder containing algorithm-related files
â””â”€â”€ assets/                # Folder for environment assets (e.g., graphics)

```
---
```
This will render the agent's behavior following the trained policy in the GridWorld environment.
