# Practice 1 & 2

Implemented algorithms include:

- **Policy Iteration**
- **Value Iteration**
- **Monte Carlo Control**
- **Temporal-Difference Learning (TD(0))**
- **SARSA**
- **Q-Learning**

---

## ğŸš€ Training
To train an RL agent, run the `train.py` script with the desired algorithm and optional arguments.
```bash
python train.py --algo {algorithm} [--size SIZE] [--random] [--render]
```
**Arguments**
- --algo (str, required): Choose the learning algorithm.
  - Options: pi, vi, mc, td0, sarsa, q_learning
- --size (int, optional): Width & Height of the GridWorld. Default is 6.
- --render (flag, optional): Render the environment during training.

The trained policy will be saved in the checkpoints/ directory as a .pkl file.


![Output](assets/_img/animation.gif)

---

## ğŸ–¼ï¸ Rendering a Trained Policy
You can visualize a learned policy using the `render.py` script:
```bash
python render.py --policy {path_to_policy.pkl} [--size SIZE] [--random]
```
This will render the agent's behavior following the trained policy in the GridWorld environment.

![ex](assets/_img/render_img.png)

---

## Algorithms
<details><summary>Dynamic Programing</summary>
## Policy Iteration
**Policy Evaluation**  
![ex](assets/_img/policy_eval.png)

![ex](assets/_img/policy_iteration.png)

## Value Iteration
![ex](assets/_img/value_iter.png)
</details>

---

## ğŸŒ GridWorld

The GridWorld environment is a 2D grid-based world where each cell can be one of the following types:

- ğŸŸ© **Normal**: The agent can move to a normal cell with a reward of -1.
- ğŸ§± **Wall**: The agent cannot move into a wall cell. The agent stays in its current position and receives a reward of -1.
- â˜ ï¸ **Trap**: If the agent moves into a trap cell, it receives a reward of -100, and the episode ends.
- ğŸ¯ **Goal**: If the agent reaches the goal cell, it receives a reward of 100, and the episode ends.

### ğŸ“ Grid Dimensions

- The grid size can range from **5x5** to **10x10**.

### ğŸƒâ€â™‚ï¸ Actions

- The agent has 4 possible actions:  
  - â¬†ï¸ **Move Up**  
  - â¬‡ï¸ **Move Down**  
  - â¬…ï¸ **Move Left**  
  - â¡ï¸ **Move Right**

---

## ğŸ“ Folder Structure

```bash
.
â”œâ”€â”€ train.py               # Main training script
â”œâ”€â”€ render.py              # Visualization script
â”œâ”€â”€ checkpoints/           # Saved policy files
â”œâ”€â”€ env/                   # GridWorld environment
â”‚   â””â”€â”€ maps/              # Predefined map configurations
â”œâ”€â”€ outputs/               # Plotted value tables and action maps
â”œâ”€â”€ venv/                  # Virtual environment folder
â”œâ”€â”€ algos/                 # Folder containing algorithm-related files
â””â”€â”€ assets/                # Folder for environment assets (e.g., graphics)

```